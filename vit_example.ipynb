{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/RustamyF/vision-transformer/blob/master/vit_example.ipynb)\n"
      ],
      "metadata": {
        "id": "6ORCnWA_30f2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8VbaIvlyHVB",
        "outputId": "fab803d5-1129-4aad-bace-9750e3e385ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-14 21:00:57--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 74.125.24.128, 142.250.4.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘pets’\n",
            "\n",
            "pets                100%[===================>]  65.43M  20.0MB/s    in 4.1s    \n",
            "\n",
            "2023-02-14 21:01:01 (16.0 MB/s) - ‘pets’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O pets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RustamyF/vision-transformer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfnUeUsMibys",
        "outputId": "503caea7-c938-4b2c-da1a-07f5af3ca752"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision-transformer'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 30 (delta 7), reused 28 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), 118.22 KiB | 9.09 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip pets\n",
        "# !rm pets\n",
        "# !mv -v cats_and_dogs_filtered/validation/dogs/* cats_and_dogs_filtered/train/dogs/\n",
        "# !mv -v cats_and_dogs_filtered/validation/cats/* cats_and_dogs_filtered/train/cats/"
      ],
      "metadata": {
        "id": "q9AFhZQKkfI9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vision_tr.simple_vit import Transformer"
      ],
      "metadata": {
        "id": "KrYTcGVxjYE_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "class LoadData:\n",
        "    def __init__(self):\n",
        "        self.cat_path = 'cats_and_dogs_filtered/train/cats'\n",
        "        self.dog_path = 'cats_and_dogs_filtered/train/dogs'\n",
        "\n",
        "    def delete_non_jpeg_files(self, directory):\n",
        "        for filename in os.listdir(directory):\n",
        "            if not filename.endswith('.jpg') and not filename.endswith('.jpeg'):\n",
        "                file_path = os.path.join(directory, filename)\n",
        "                try:\n",
        "                    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                        os.unlink(file_path)\n",
        "                    elif os.path.isdir(file_path):\n",
        "                        shutil.rmtree(file_path)\n",
        "                    print('deleted', file_path)\n",
        "                except Exception as e:\n",
        "                    print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "    def data(self):\n",
        "        self.delete_non_jpeg_files(self.dog_path)\n",
        "        self.delete_non_jpeg_files(self.cat_path)\n",
        "\n",
        "        dog_list = os.listdir(self.dog_path)\n",
        "        dog_list = [(os.path.join(self.dog_path, i), 1) for i in dog_list]\n",
        "\n",
        "        cat_list = os.listdir(self.cat_path)\n",
        "        cat_list = [(os.path.join(self.cat_path, i), 0) for i in cat_list]\n",
        "\n",
        "        total_list = cat_list + dog_list\n",
        "\n",
        "        train_list, test_list = train_test_split(total_list, test_size=0.2)\n",
        "        train_list, val_list = train_test_split(train_list, test_size=0.2)\n",
        "        print('train list', len(train_list))\n",
        "        print('test list', len(test_list))\n",
        "        print('val list', len(val_list))\n",
        "        return train_list, test_list, val_list\n",
        "\n",
        "\n",
        "# data Augumentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    # dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "\n",
        "    # load an one of images\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.file_list[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_transformed = self.transform(img)\n",
        "        return img_transformed, label\n",
        "\n",
        "\n",
        "class Cnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Cnn, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(3 * 3 * 64, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(10, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lr = 0.001  # learning_rate\n",
        "    batch_size = 100  # we will use mini-batch method\n",
        "    epochs = 10  # How much to train a model\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    torch.manual_seed(1234)\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.manual_seed_all(1234)\n",
        "\n",
        "    print(device)\n",
        "\n",
        "    load_data = LoadData()\n",
        "\n",
        "    train_list, test_list, val_list = load_data.data()\n",
        "\n",
        "    train_data = dataset(train_list, transform=transform)\n",
        "    test_data = dataset(test_list, transform=transform)\n",
        "    val_data = dataset(val_list, transform=transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = Cnn().to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_accuracy = 0\n",
        "\n",
        "        for data, label in train_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "            epoch_accuracy += acc / len(train_loader)\n",
        "            epoch_loss += loss / len(train_loader)\n",
        "\n",
        "        print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch + 1, epoch_accuracy, epoch_loss))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            epoch_val_accuracy = 0\n",
        "            epoch_val_loss = 0\n",
        "            for data, label in val_loader:\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "\n",
        "                val_output = model(data)\n",
        "                val_loss = criterion(val_output, label)\n",
        "\n",
        "                acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
        "                epoch_val_accuracy += acc / len(val_loader)\n",
        "                epoch_val_loss += val_loss / len(val_loader)\n",
        "\n",
        "            print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch + 1, epoch_val_accuracy, epoch_val_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TChHpDa1jtRD",
        "outputId": "6ce1ab9d-373a-47a0-f2b0-c4d9441fb262"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "train list 1920\n",
            "test list 600\n",
            "val list 480\n",
            "Epoch : 1, train accuracy : 0.565000057220459, train loss : 0.6857559680938721\n",
            "Epoch : 1, val_accuracy : 0.6000000238418579, val_loss : 0.6539488434791565\n",
            "Epoch : 2, train accuracy : 0.6114999651908875, train loss : 0.6514831781387329\n",
            "Epoch : 2, val_accuracy : 0.6330000162124634, val_loss : 0.6340216398239136\n",
            "Epoch : 3, train accuracy : 0.6214999556541443, train loss : 0.6426859498023987\n",
            "Epoch : 3, val_accuracy : 0.6399999856948853, val_loss : 0.6335686445236206\n",
            "Epoch : 4, train accuracy : 0.6580000519752502, train loss : 0.6204438209533691\n",
            "Epoch : 4, val_accuracy : 0.6539999842643738, val_loss : 0.6156217455863953\n",
            "Epoch : 5, train accuracy : 0.652999997138977, train loss : 0.6182745099067688\n",
            "Epoch : 5, val_accuracy : 0.6654999852180481, val_loss : 0.6166585683822632\n",
            "Epoch : 6, train accuracy : 0.6804999113082886, train loss : 0.5977426171302795\n",
            "Epoch : 6, val_accuracy : 0.6725000143051147, val_loss : 0.611417293548584\n",
            "Epoch : 7, train accuracy : 0.6719999313354492, train loss : 0.6007359027862549\n",
            "Epoch : 7, val_accuracy : 0.7030000686645508, val_loss : 0.5907251834869385\n",
            "Epoch : 8, train accuracy : 0.6904999613761902, train loss : 0.5744299292564392\n",
            "Epoch : 8, val_accuracy : 0.6929999589920044, val_loss : 0.5822156071662903\n",
            "Epoch : 9, train accuracy : 0.6895000338554382, train loss : 0.5791221261024475\n",
            "Epoch : 9, val_accuracy : 0.643500030040741, val_loss : 0.5970439910888672\n",
            "Epoch : 10, train accuracy : 0.6795000433921814, train loss : 0.5869641304016113\n",
            "Epoch : 10, val_accuracy : 0.6885000467300415, val_loss : 0.5905383825302124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from vision_tr.simple_vit import ViT\n",
        "# from vit_pytorch.efficient import ViT\n",
        "from linformer import Linformer\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "\n",
        "# from linformer import Linformer\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# from vit_pytorch.efficient import ViT\n",
        "\n",
        "\n",
        "class LoadData:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cat_path = 'cats_and_dogs_filtered/train/cats'\n",
        "        self.dog_path = 'cats_and_dogs_filtered/train/dogs'\n",
        "\n",
        "    def delete_non_jpeg_files(self, directory):\n",
        "        for filename in os.listdir(directory):\n",
        "            if not filename.endswith('.jpg') and not filename.endswith('.jpeg'):\n",
        "                file_path = os.path.join(directory, filename)\n",
        "                try:\n",
        "                    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                        os.unlink(file_path)\n",
        "                    elif os.path.isdir(file_path):\n",
        "                        shutil.rmtree(file_path)\n",
        "                    print('deleted', file_path)\n",
        "                except Exception as e:\n",
        "                    print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "    def data(self):\n",
        "        self.delete_non_jpeg_files(self.dog_path)\n",
        "        self.delete_non_jpeg_files(self.cat_path)\n",
        "\n",
        "        dog_list = os.listdir(self.dog_path)\n",
        "        dog_list = [(os.path.join(self.dog_path, i), 1) for i in dog_list]\n",
        "\n",
        "        cat_list = os.listdir(self.cat_path)\n",
        "        cat_list = [(os.path.join(self.cat_path, i), 0) for i in cat_list]\n",
        "\n",
        "        total_list = cat_list + dog_list\n",
        "\n",
        "        train_list, test_list = train_test_split(total_list, test_size=0.2)\n",
        "        train_list, val_list = train_test_split(train_list, test_size=0.2)\n",
        "        print('train list', len(train_list))\n",
        "        print('test list', len(test_list))\n",
        "        print('val list', len(val_list))\n",
        "        return train_list, test_list, val_list\n",
        "\n",
        "\n",
        "# data Augumentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    # dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "\n",
        "    # load an one of images\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.file_list[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_transformed = self.transform(img)\n",
        "        return img_transformed, label\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Training settings\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "    lr = 3e-5\n",
        "    gamma = 0.7\n",
        "    seed = 42\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    torch.manual_seed(1234)\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.manual_seed_all(1234)\n",
        "\n",
        "    print(device)\n",
        "\n",
        "    load_data = LoadData()\n",
        "\n",
        "    train_list, test_list, val_list = load_data.data()\n",
        "\n",
        "    train_data = dataset(train_list, transform=transform)\n",
        "    test_data = dataset(test_list, transform=transform)\n",
        "    val_data = dataset(val_list, transform=transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
        "    model = ViT(\n",
        "        image_size=224,\n",
        "        patch_size=32,\n",
        "        num_classes=2,\n",
        "        dim=128,\n",
        "        depth=12,\n",
        "        heads=8,\n",
        "        mlp_dim=1024,\n",
        "        dropout=0.1,\n",
        "        emb_dropout=0.1,\n",
        "    ).to(device)\n",
        "\n",
        "    # loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    # scheduler\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "\n",
        "    epochs = 20\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_accuracy = 0\n",
        "\n",
        "        for data, label in train_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "            epoch_accuracy += acc / len(train_loader)\n",
        "            epoch_loss += loss / len(train_loader)\n",
        "\n",
        "        print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch + 1, epoch_accuracy, epoch_loss))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            epoch_val_accuracy = 0\n",
        "            epoch_val_loss = 0\n",
        "            for data, label in val_loader:\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "\n",
        "                val_output = model(data)\n",
        "                val_loss = criterion(val_output, label)\n",
        "\n",
        "                acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
        "                epoch_val_accuracy += acc / len(val_loader)\n",
        "                epoch_val_loss += val_loss / len(val_loader)\n",
        "\n",
        "            print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch + 1, epoch_val_accuracy, epoch_val_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3CfkEoQjwfr",
        "outputId": "76b279fc-994e-4354-8740-e70584888042"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "train list 1920\n",
            "test list 600\n",
            "val list 480\n",
            "Epoch : 1, train accuracy : 0.4994792342185974, train loss : 0.7245917320251465\n",
            "Epoch : 1, val_accuracy : 0.490234375, val_loss : 0.7057166695594788\n",
            "Epoch : 2, train accuracy : 0.5265625715255737, train loss : 0.6961603164672852\n",
            "Epoch : 2, val_accuracy : 0.546875, val_loss : 0.6814125776290894\n",
            "Epoch : 3, train accuracy : 0.5187500715255737, train loss : 0.6930896043777466\n",
            "Epoch : 3, val_accuracy : 0.515625, val_loss : 0.6940701603889465\n",
            "Epoch : 4, train accuracy : 0.5375000238418579, train loss : 0.6871858835220337\n",
            "Epoch : 4, val_accuracy : 0.53515625, val_loss : 0.6902409791946411\n",
            "Epoch : 5, train accuracy : 0.5598958730697632, train loss : 0.6862000823020935\n",
            "Epoch : 5, val_accuracy : 0.54296875, val_loss : 0.6816489696502686\n",
            "Epoch : 6, train accuracy : 0.5598958730697632, train loss : 0.6801536083221436\n",
            "Epoch : 6, val_accuracy : 0.537109375, val_loss : 0.6803664565086365\n",
            "Epoch : 7, train accuracy : 0.55364590883255, train loss : 0.6809118390083313\n",
            "Epoch : 7, val_accuracy : 0.572265625, val_loss : 0.6767404079437256\n",
            "Epoch : 8, train accuracy : 0.550000011920929, train loss : 0.6830349564552307\n",
            "Epoch : 8, val_accuracy : 0.59765625, val_loss : 0.66758793592453\n",
            "Epoch : 9, train accuracy : 0.5708333253860474, train loss : 0.6750744581222534\n",
            "Epoch : 9, val_accuracy : 0.54296875, val_loss : 0.6844791173934937\n",
            "Epoch : 10, train accuracy : 0.5765625834465027, train loss : 0.676020622253418\n",
            "Epoch : 10, val_accuracy : 0.60546875, val_loss : 0.661860466003418\n",
            "Epoch : 11, train accuracy : 0.5776041746139526, train loss : 0.6704158782958984\n",
            "Epoch : 11, val_accuracy : 0.599609375, val_loss : 0.6600018739700317\n",
            "Epoch : 12, train accuracy : 0.5755208134651184, train loss : 0.6709128618240356\n",
            "Epoch : 12, val_accuracy : 0.5859375, val_loss : 0.6593186259269714\n",
            "Epoch : 13, train accuracy : 0.589062511920929, train loss : 0.6668018698692322\n",
            "Epoch : 13, val_accuracy : 0.61328125, val_loss : 0.6488369107246399\n",
            "Epoch : 14, train accuracy : 0.5901041626930237, train loss : 0.6655963659286499\n",
            "Epoch : 14, val_accuracy : 0.57421875, val_loss : 0.6661496162414551\n",
            "Epoch : 15, train accuracy : 0.5796874761581421, train loss : 0.6640631556510925\n",
            "Epoch : 15, val_accuracy : 0.580078125, val_loss : 0.6659587621688843\n",
            "Epoch : 16, train accuracy : 0.5932291746139526, train loss : 0.6546841263771057\n",
            "Epoch : 16, val_accuracy : 0.611328125, val_loss : 0.637117862701416\n",
            "Epoch : 17, train accuracy : 0.5994791984558105, train loss : 0.6537193655967712\n",
            "Epoch : 17, val_accuracy : 0.609375, val_loss : 0.6477311849594116\n",
            "Epoch : 18, train accuracy : 0.590624988079071, train loss : 0.6573920249938965\n",
            "Epoch : 18, val_accuracy : 0.587890625, val_loss : 0.6448151469230652\n",
            "Epoch : 19, train accuracy : 0.6015625596046448, train loss : 0.6448671817779541\n",
            "Epoch : 19, val_accuracy : 0.615234375, val_loss : 0.6461520195007324\n",
            "Epoch : 20, train accuracy : 0.5979167222976685, train loss : 0.6532052755355835\n",
            "Epoch : 20, val_accuracy : 0.59375, val_loss : 0.6412197351455688\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
